#!/usr/bin/python -tt
# This file is part of Ansible
#
# Ansible is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# Ansible is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with Ansible.  If not, see <http://www.gnu.org/licenses/>.

DOCUMENTATION = '''
---
module: s3
short_description: idempotent s3 module for bucket create/delete, get and put operations
description:
    - Creates and deletes and S3 bucket. Can be used to perform PUT/GET with a filename argument into a bucket based on supplied key (basically a directory). This module has a dependency on python-boto.
version_added: "1.1"
options:
  bucket:
    description:
      - bucket you wish to create/delete or upload/fetch from. 
    required: true
    default: null 
    aliases: []
  key:
    description:
      - key name (directory name) to use within the bucket.
    required: true
    default: null
    aliases: []
  action:
    description:
      - Action to perform, GET or PUT.
    required: false
    default: null
    aliases: []
  filename:
    description:
      - filename for PUT or GET operation.
    required: false
    default: null
    aliases: []
  expiry:
    description:
      - expiry period (in seconds) for returned download URL
    required: false
    default: 600
    aliases: []
examples:
   - code: 's3 bucket=mybucket key=mystuff action=put filename=/path/to/file state=present'
     description: "Simple playbook example"
requirements: [ "boto" ]
author: Lester Wade
'''

import sys
#import time
import os
import urlparse

try:
    import boto
#    import boto.s3 
except ImportError:
    print "failed=True msg='boto required for this module'"
    sys.exit(1)

def main():
    module = AnsibleModule(
        argument_spec = dict(
            bucket = dict(),
            key = dict(),
            action = dict(choices=['put', 'get']),
            filename = dict(),
            state  = dict(required=True, choices=['present', 'absent']),
            expiry = dict(required=False, default=600),
            s3_url = dict(aliases=['S3_URL']),
            ec2_secret_key = dict(aliases=['EC2_SECRET_KEY']),
            ec2_access_key = dict(aliases=['EC2_ACCESS_KEY']),
        )
    )

    bucket_name = module.params.get('bucket')
    key_name = module.params.get('key')
    action = module.params.get('action')
    filename = os.path.expanduser(module.params['filename'])
    state = module.params.get('state')
    expiry = int(module.params['expiry'])
    s3_url = module.params.get('s3_url')
    ec2_secret_key = module.params.get('ec2_secret_key')
    ec2_access_key = module.params.get('ec2_access_key')

    # allow eucarc environment variables to be used if ansible vars aren't set
    
    if not s3_url and 'S3_URL' in os.environ:
        s3_url = os.environ['S3_URL']
    if not ec2_secret_key and 'EC2_SECRET_KEY' in os.environ:
        ec2_secret_key = os.environ['EC2_SECRET_KEY']
    if not ec2_access_key and 'EC2_ACCESS_KEY' in os.environ:
        ec2_access_key = os.environ['EC2_ACCESS_KEY']

    # If we have an S3_URL env var set, this is likely to be Walrus, so change connection method
    if 'S3_URL' in os.environ:
        try:
            walrus = urlparse.urlparse(s3_url).hostname
            s3 = boto.connect_walrus(walrus, ec2_access_key, ec2_secret_key)
        except boto.exception.NoAuthHandlerFound, e:
            module.fail_json(msg = str(e))
    else:
        try:
            s3 = boto.connect_s3(ec2_access_key, ec2_secret_key)
        except boto.exception.NoAuthHandlerFound, e:
            module.fail_json(msg = str(e))
    
    # Lets be clear about the assumed state to start with:
    bucket_exists = False
    key_exists = False

    # Lets get some information from the s3 connection, including bucket check ...
    bucket = s3.lookup(bucket_name)
    if bucket:
        bucket_exists = True
    else:
        bucket_exists = False
    
    # Lets list the contents
    if bucket_exists == True:
        bucket_contents = bucket.list()

    # Check filename is valid if doing a PUT
    if action != 'get':
        if not os.path.exists(filename):
            module.fail_json(msg="Source %s cannot be found" % (filename))

    # Default to setting the key to the same as the filename on PUT if no key is specified
    if key_name is None:
        if action == 'get':
            key_name = os.path.basename(filename)
        if action == 'put':
            key_name = os.path.basename(filename)

    # If state is present and bucket exists, lets see if key exists to determine complete state
    # TO DO - need to have a better check than just keyname (some sum or name + filesize, or?)
    if state == 'present' and bucket_exists == True:
        try:
            key_check = bucket.get_key(key_name)
            if key_check is None:
                key_exists = False
            else:
                key_exists = True
                changed = False
                module.exit_json(msg="Bucket and key already exist", changed=False)
                sys.exit(0)
        except s3.provider.storage_response_error, e:
            module.fail_json(msg= str(e))


    # If state is present but the bucket doesn't exist, create it ...
    if state == 'present' and bucket_exists == False:
        try:
            bucket = s3.create_bucket(bucket_name)
            bucket_exists = True
            changed = True
        except s3.provider.storage_create_error, e:
            module.fail_json(msg = str(e))


    # If state is absent and the bucket exists already, delete it (recursively) ...
    if state == 'absent' and bucket_exists == True:
        try:
            for contents in bucket.list():
                bucket.delete_key(contents)
                s3.delete_bucket(bucket)
                changed = True
                module.exit_json(msg="Bucket and key removed", changed=True)
                sys.exit(0)
        except s3.provider.storage_response_error, e:
            module.fail_json(msg= str(e))

    # If the bucket exists and we have an action specified along with filename (or key from above), do stuff ...
    if bucket_exists == True and key_exists == False:
       if action in ['put','get']: 
           if action == 'put':
                try:
                    key = bucket.new_key(key_name)  
                    key.set_contents_from_filename(filename)
                    url = key.generate_url(expiry)
                except s3.provider.storage_copy_error, e:
                    module.fail_json(msg= str(e))
           # for the GET, if filename is set it will download to that path
           if action == 'get':
               if filename:
                    try:
                        getkey = bucket.lookup(key_name)
                        getkey.get_contents_to_filename(filename)
                        url = getkey.generate_url(expiry)
                    except s3.provider.storage_copy_error, e:
                        module.fail_json(msg= str(e))

    # return a time-expired URL for access later in other plays etc.
    print json.dumps({
        "url": url
    })
    sys.exit(0)

# this is magic, see lib/ansible/module_common.py
#<<INCLUDE_ANSIBLE_MODULE_COMMON>>

main()
